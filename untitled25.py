# -*- coding: utf-8 -*-
"""Untitled25.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HRUuuYg5rmWikH0LUvxHy7VM8viz4vWb
"""

import pandas as pd

# Load the dataset
file_path = "heart_attack_youngsters_india.csv"
df = pd.read_csv(file_path)

# Display basic information and first few rows
df.info(), df.head()

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score, classification_report



# Encode categorical variables
label_encoders = {}
for col in df.select_dtypes(include=['object']).columns:
    if col != 'Heart Attack Likelihood':  # Keep target variable separate
        label_encoders[col] = LabelEncoder()
        df[col] = label_encoders[col].fit_transform(df[col])

# Convert target variable to binary (0 = No, 1 = Yes)
df['Heart Attack Likelihood'] = df['Heart Attack Likelihood'].map({'No': 0, 'Yes': 1})

# Define features and target
X = df.drop(columns=['Heart Attack Likelihood'])
y = df['Heart Attack Likelihood']

# Split into training and testing sets (80-20 split)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# Standardize numerical features
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Train multiple models
models = {
    "Random Forest": RandomForestClassifier(n_estimators=100, random_state=42),
    "SVM": SVC(kernel='rbf', probability=True),
    "XGBoost": XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)
}

# Evaluate models
results = {}
for name, model in models.items():
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    results[name] = accuracy
    print(f"{name} Accuracy: {accuracy:.4f}")
    print(classification_report(y_test, y_pred))

# Identify the best model
best_model_name = max(results, key=results.get)
print(f"Best Model: {best_model_name} with Accuracy: {results[best_model_name]:.4f}")

import seaborn as sns
import matplotlib.pyplot as plt

plt.figure(figsize=(12, 8))
sns.heatmap(df.corr(), annot=True, cmap="coolwarm", fmt=".2f")
plt.title("Feature Correlation Heatmap")
plt.show()

sns.countplot(x=df["Heart Attack Likelihood"], palette="pastel")
plt.title("Distribution of Heart Attack Likelihood")
plt.xlabel("Likelihood (0 = No, 1 = Yes)")
plt.ylabel("Count")
plt.show()

df.columns



import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.stats import chi2_contingency, ttest_ind
import statsmodels.api as sm

# Load data
df = pd.read_csv("heart_attack_youngsters_india.csv")

# Filter Gen Z (assuming age <=24)
df_genz = df[df["Age"] <= 30]

# --- Convert 'Heart Attack Likelihood' to numerical before groupby ---
# This is crucial to avoid the TypeError
df_genz['Heart Attack Likelihood'] = df_genz['Heart Attack Likelihood'].map({'No': 0, 'Yes': 1})

# --- 1. Descriptive Analysis ---
print("=== Descriptive Statistics ===")
# Prevalence of risk factors
print("Sleep <6hrs:", round((df_genz["Sleep Duration (hrs/day)"] < 6).mean() * 100, 1), "%")
print("Screen Time >4hrs:", round((df_genz["Screen Time (hrs/day)"] > 4).mean() * 100, 1), "%")
print("Unhealthy Diet:", round((df_genz["Diet Type"] == "Unhealthy").mean() * 100, 1), "%")
print("Low Activity:", round((df_genz["Physical Activity Level"] == "Low").mean() * 100, 1), "%")
print("High Stress:", round((df_genz["Stress Level"] == "High").mean() * 100, 1), "%")

# Heart attack rates by risk factors
print("\n=== Heart Attack Likelihood by Risk Factor ===")
print("Screen Time >4hrs:")
print(df_genz.groupby("Screen Time (hrs/day)")["Heart Attack Likelihood"].mean())
print("\nSleep <6hrs:")
print(df_genz.groupby("Sleep Duration (hrs/day)")["Heart Attack Likelihood"].mean())

# --- 2. Correlation Analysis ---
# ... (rest of the code remains the same)

# Filter Gen Z (adjust age threshold if needed)
df_genz = df[df["Age"] <= 30]

# --- 1. Distribution of Heart Attack Likelihood ---
plt.figure(figsize=(8, 5))
sns.countplot(x="Heart Attack Likelihood", data=df_genz)
plt.title("Distribution of Heart Attack Cases in Gen Z")
plt.show()

# --- 2. Sleep Duration vs. Heart Attack Likelihood ---
plt.figure(figsize=(10, 6))
# --- Ensure 'Heart Attack Likelihood' is numerical for barplot ---
df_genz['Heart Attack Likelihood'] = df_genz['Heart Attack Likelihood'].map({'No': 0, 'Yes': 1})
sns.barplot(
    x="Sleep Duration (hrs/day)",
    y="Heart Attack Likelihood",
    data=df_genz,
    ci=None
)
plt.title("Heart Attack Likelihood by Sleep Duration")
plt.show()

# --- 3. Screen Time vs. Stress Level ---
plt.figure(figsize=(10, 6))
sns.boxplot(
    x="Stress Level",
    y="Screen Time (hrs/day)",
    data=df_genz
)
plt.title("Screen Time Distribution by Stress Level")
plt.show()

# --- 4. Diet Type vs. Cholesterol Levels ---
plt.figure(figsize=(10, 6))
sns.boxplot(
    x="Diet Type",
    y="Cholesterol Levels (mg/dL)",
    hue="Heart Attack Likelihood",
    data=df_genz
)
plt.title("Cholesterol Levels by Diet Type (Heart Attack Cases Highlighted)")
plt.show()

# --- 6. Correlation Heatmap ---
corr_vars = df_genz[[
    "Screen Time (hrs/day)",
    "Sleep Duration (hrs/day)",
    "BMI (kg/m²)",
    "Cholesterol Levels (mg/dL)",
    "Triglyceride Levels (mg/dL)",
    "Heart Attack Likelihood"  # This column likely has 'Yes'/'No'
]].copy()  # Create a copy to avoid modifying the original df_genz

# Convert 'Heart Attack Likelihood' to numerical for correlation
corr_vars["Heart Attack Likelihood"] = corr_vars["Heart Attack Likelihood"].map({"No": 0, "Yes": 1})

plt.figure(figsize=(12, 8))
sns.heatmap(corr_vars.corr(), annot=True, cmap="coolwarm", vmin=-1, vmax=1)
plt.title("Correlation Between Risk Factors and Heart Disease")
plt.show()

# --- 7. Heart Attack Cases by Risk Factor Combinations ---
# Create binary risk factors
df_genz["High Screen Time"] = (df_genz["Screen Time (hrs/day)"] > 4).astype(int)
df_genz["Poor Sleep"] = (df_genz["Sleep Duration (hrs/day)"] < 6).astype(int)
df_genz["Unhealthy Diet"] = (df_genz["Diet Type"] == "Unhealthy").astype(int)

# Aggregate data
# --- Ensure 'Heart Attack Likelihood' is numerical before groupby ---
df_genz['Heart Attack Likelihood'] = df_genz['Heart Attack Likelihood'].map({'No': 0, 'Yes': 1})  # Convert to numerical
risk_factors = df_genz.groupby(
    ["High Screen Time", "Poor Sleep", "Unhealthy Diet"]
)["Heart Attack Likelihood"].mean().reset_index()

# Plot
plt.figure(figsize=(10, 6))
sns.barplot(
    x="High Screen Time",
    y="Heart Attack Likelihood",
    hue="Unhealthy Diet",
    data=risk_factors
)
plt.title("Heart Attack Likelihood by Combined Risk Factors")
plt.show()

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, roc_auc_score
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline



# --- 1. Data Preparation ---
# Define features (X) and target (y)
X = df[[
    "Sleep Duration (hrs/day)",
    "Screen Time (hrs/day)",
    "Diet Type",
    "Stress Level",
    "Physical Activity Level",
    "BMI (kg/m²)",
    "Cholesterol Levels (mg/dL)",
    "Triglyceride Levels (mg/dL)"
]]
# --- Ensure 'Heart Attack Likelihood' is numerical for barplot ---
df['Heart Attack Likelihood'] = df['Heart Attack Likelihood'].map({'No': 0, 'Yes': 1})
# --- Drop rows with NaN in 'Heart Attack Likelihood' ---
df = df.dropna(subset=['Heart Attack Likelihood'])

y = df["Heart Attack Likelihood"]  # Binary encoding

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# --- 2. Preprocessing Pipeline ---
# Categorical features (to encode)
cat_cols = ["Diet Type", "Stress Level", "Physical Activity Level"]
# Numeric features (to scale)
num_cols = ["Sleep Duration (hrs/day)", "Screen Time (hrs/day)", "BMI (kg/m²)",
            "Cholesterol Levels (mg/dL)", "Triglyceride Levels (mg/dL)"]

# Preprocessor
preprocessor = ColumnTransformer(
    transformers=[
        ("num", StandardScaler(), num_cols),
        ("cat", OneHotEncoder(), cat_cols)
    ])

# --- 3. Model Training ---
# Pipeline with logistic regression
model = Pipeline(steps=[
    ("preprocessor", preprocessor),
    ("classifier", LogisticRegression(max_iter=1000))
])

model.fit(X_train, y_train)

# --- 4. Model Evaluation ---
y_pred = model.predict(X_test)
y_pred_proba = model.predict_proba(X_test)[:, 1]

print("=== Model Performance ===")
print(f"Accuracy: {accuracy_score(y_test, y_pred):.2f}")
print(f"ROC-AUC: {roc_auc_score(y_test, y_pred_proba):.2f}")
print("\nClassification Report:")
print(classification_report(y_test, y_pred))

# --- 5. Feature Importance ---
# Extract coefficients (for interpretation)
log_reg = model.named_steps["classifier"]
feature_names = (preprocessor.named_transformers_["cat"].get_feature_names_out(cat_cols)).tolist()
feature_names = num_cols + feature_names

coefficients = pd.DataFrame({
    "Feature": feature_names,
    "Coefficient": log_reg.coef_[0]
}).sort_values(by="Coefficient", ascending=False)

print("\n=== Top Risk Factors ===")
print(coefficients.head(10))

import matplotlib.pyplot as plt
import seaborn as sns

# Feature importance from logistic regression coefficients
coefficients = pd.DataFrame({
    "Feature": feature_names,
    "Coefficient": log_reg.coef_[0]
}).sort_values(by="Coefficient", ascending=False)

# Plot top 10 features
plt.figure(figsize=(10, 6))
sns.barplot(
    x="Coefficient",
    y="Feature",
    data=coefficients.head(10),
    palette="viridis"
)
plt.title("Top Risk Factors for Heart Attack Likelihood")
plt.xlabel("Coefficient (Positive = Higher Risk)")
plt.ylabel("Feature")
plt.show()

from sklearn.metrics import roc_curve

# Compute ROC curve
fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)

# Plot ROC curve
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, label=f"ROC Curve (AUC = {roc_auc_score(y_test, y_pred_proba):.2f})")
plt.plot([0, 1], [0, 1], "k--", label="Random Guess")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve")
plt.legend(loc="lower right")
plt.show()

from sklearn.metrics import ConfusionMatrixDisplay

# Plot confusion matrix
ConfusionMatrixDisplay.from_predictions(
    y_test, y_pred, cmap="Blues", display_labels=["No", "Yes"]
)
plt.title("Confusion Matrix")
plt.show()

# Distribution of predicted probabilities
plt.figure(figsize=(10, 6))
sns.histplot(y_pred_proba, bins=20, kde=True, color="purple")
plt.axvline(0.5, color="red", linestyle="--", label="Decision Threshold (0.5)")
plt.title("Distribution of Predicted Probabilities")
plt.xlabel("Predicted Probability of Heart Attack")
plt.ylabel("Frequency")
plt.legend()
plt.show()

from sklearn.calibration import calibration_curve

# Compute calibration curve
prob_true, prob_pred = calibration_curve(y_test, y_pred_proba, n_bins=10)

# Plot calibration curve
plt.figure(figsize=(8, 6))
plt.plot(prob_pred, prob_true, marker="o", label="Calibration Curve")
plt.plot([0, 1], [0, 1], "k--", label="Perfect Calibration")
plt.xlabel("Predicted Probability")
plt.ylabel("Actual Probability")
plt.title("Calibration Curve")
plt.legend()
plt.show()